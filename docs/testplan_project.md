# План тестирования проекта (v2)

## 1. Введение

Данный документ описывает план сквозного (End-to-End) тестирования распределённой микросервисной системы для онлайн-курсов с автоматической проверкой программных заданий. План тестирования составлен на основе актуальной Postman-коллекции с независимыми тестами отправки решений (submissions), включая позитивные и негативные сценарии.

Цель плана — подтвердить корректность работы API, надёжность проверки пользовательского кода, а также продемонстрировать устойчивость системы к ошибочным данным.

---

## 2. Область тестирования

В рамках тестирования проверяются следующие компоненты системы:

* API Gateway (единая точка входа)
* Course Service (модули и задачи)
* Judge Service (проверка пользовательского кода)
* PostgreSQL (хранение задач, тест-кейсов и результатов)

Тестирование проводится через публичный HTTP API, доступный через Kubernetes NodePort.

---

## 3. Архитектура тестируемой системы (кратко)

Система построена по микросервисной архитектуре и развёрнута в Kubernetes-кластере:

* Клиент взаимодействует с системой через API Gateway
* API Gateway маршрутизирует запросы в Course Service и Judge Service
* Course Service отвечает за данные курсов и задач
* Judge Service выполняет и проверяет пользовательский код
* Все сервисы используют общую базу данных PostgreSQL

---

## 4. Общие предусловия

Перед запуском тестов должны выполняться следующие условия:

1. Kubernetes-кластер запущен и доступен
2. Все pod’ы находятся в состоянии `Running`
3. API Gateway доступен по адресу:

   * `http://localhost:30080`
4. В базе данных присутствуют задачи с идентификаторами **1–17** и соответствующие test cases
5. В API Gateway корректно настроена маршрутизация:

   * `POST /tasks/{id}/submissions` → Judge Service
   * `GET /submissions/{id}` → Judge Service
6. Для POST-запросов используется заголовок идемпотентности `X-Idempotency-Key`

---

## 5. Используемые инструменты

* Postman (ручной запуск и отладка)
* Postman Runner / Newman (автоматический прогон)
* Kubernetes CLI (`kubectl`) для контроля состояния системы

---

## 6. Smoke-тестирование

### 6.1 Проверка доступности системы

**Цель:** убедиться, что система доступна через API Gateway.

**Запрос:**

```
GET /healthz
```

**Ожидаемый результат:**

* HTTP статус `200 OK`

---

## 7. Базовые API-тесты

### 7.1 Получение списка задач

**Запрос:**

```
GET /tasks
```

**Ожидаемый результат:**

* HTTP статус `200 OK`
* Ответ содержит непустой массив задач

---

### 7.2 Получение списка модулей

**Запрос:**

```
GET /modules
```

**Ожидаемый результат:**

* HTTP статус `200 OK`
* Ответ содержит непустой массив модулей

---

## 8. Сквозные тесты отправки решений (Submissions)

### 8.1 Общий сценарий проверки решения

Каждый submission-тест выполняет следующий сценарий:

1. Отправка решения задачи
2. Получение идентификатора submission
3. Периодический опрос статуса проверки (polling)
4. Получение финального результата проверки

**Формат запроса:**

```
POST /tasks/{taskId}/submissions
Headers:
  Content-Type: application/json
  X-Idempotency-Key: <uuid>
Body:
  {"code": "<python-code>", "language": "python"}
```

---

### 8.2 Позитивные сценарии (ожидается PASSED)

**Цель:** подтвердить корректную работу пайплайна проверки для валидных решений.

**Набор тестов:**

* Задачи с `taskId` от **1 до 17**
* Для каждой задачи используется эталонное решение, соответствующее test cases в базе данных

**Ожидаемый результат для каждого теста:**

* POST-запрос возвращает `200` или `201`
* В ответе присутствуют поля `id`, `taskId`, `status`
* После polling финальный статус проверки — **`PASSED`**

**Примечание:**

* Все тесты независимы
* Каждый тест создаёт собственный submission и не использует данные других тестов

---

### 8.3 Негативный сценарий (ожидается FAILED)

**Цель:** убедиться, что система корректно обрабатывает неправильные решения.

**Запрос:**

```
POST /tasks/1/submissions
Body:
  {"code": "print('WRONG_ANSWER')", "language": "python"}
```

**Ожидаемый результат:**

* POST-запрос возвращает `200` или `201`
* После polling финальный статус проверки — **`FAILED`**

---

## 9. Порядок выполнения тестов

Рекомендуемый порядок прогона:

1. Smoke-тест (`/healthz`)
2. Базовые API-тесты (`/tasks`, `/modules`)
3. Позитивные submission-тесты (tasks 1–17, в любом порядке)
4. Негативный submission-тест

---

## 10. Критерии успешного прохождения тестирования

Тестирование считается успешным, если:

* Все smoke и базовые API-тесты завершаются с кодом `200 OK`
* Все позитивные submission-тесты завершаются со статусом `PASSED`
* Негативный submission-тест завершается со статусом `FAILED`
* Polling не завершается по таймауту

---

## 11. Вывод

Данный план тестирования подтверждает корректную работу распределённой системы, надёжность механизма автоматической проверки пользовательского кода и устойчивость API к ошибочным входным данным. Независимость тестов обеспечивает воспроизводимость результатов и удобство автоматизированного прогона.
